# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1meEhWsWOLzXM9_vudn1IUbJOiQysnCRs
"""

import streamlit as st
from transformers import pipeline

# --- Configuration and Caching ---

# Set Streamlit page configuration
st.set_page_config(
    page_title="Hugging Face Transformer Demos",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Use st.cache_resource to load models once and improve performance
# This is crucial as models are large and take time to load
@st.cache_resource
def load_pipelines():
    """Load all necessary NLP pipelines."""

    st.spinner("Loading NLP models... This might take a moment!")
    try:
        pipelines = {
            # Text Generation (gpt2 from your script)
            "text_gen": pipeline("text-generation", model="gpt2"),
            # Summarization (facebook/bart-large-cnn from your script)
            "summarizer": pipeline("summarization", model="facebook/bart-large-cnn"),
            # Sentiment Analysis (default model from your script)
            "sentiment": pipeline("sentiment-analysis"),
            # Named Entity Recognition (dslim/bert-base-NER from your script)
            "ner": pipeline("ner", model="dslim/bert-base-NER", aggregation_strategy="simple"),
            # Grammar Correction (prithivida/grammar_error_correcter_v1 from your script)
            "grammar": pipeline("text2text-generation", model="prithivida/grammar_error_correcter_v1"),
        }
        return pipelines
    except Exception as e:
        st.error(f"Error loading models: {e}. Please ensure you have all dependencies.")
        return None

# Load all pipelines once
pipes = load_pipelines()

# --- Streamlit UI ---

st.title("üß† NLP Tasks with Hugging Face Transformers")
st.markdown("Demonstration based on your gen_ai_with_transformer_library_.py script.")

# Sidebar for task selection
task = st.sidebar.selectbox(
    "*Select an NLP Task*",
    [
        "Text Generation",
        "Summarization",
        "Sentiment Analysis",
        "Named Entity Recognition (NER)",
        "Grammar Correction"
    ]
)
st.sidebar.markdown("---")
st.sidebar.info("Models are loaded only once using @st.cache_resource for fast performance!")

if not pipes:
    st.stop()

# --- Task-Specific Logic ---

# 1. Text Generation
if task == "Text Generation":
    st.header("üìù Text Generation (GPT-2)")
    st.markdown("Enter a starting prompt, and GPT-2 will complete the text.")

    input_text = st.text_area(
        "Enter your prompt:",
        "The future of artificial intelligence is",
        height=100
    )
    max_len = st.slider("Max Length of Generated Text", 50, 500, 200)

    if st.button("Generate Text"):
        with st.spinner("Generating..."):
            result = pipes["text_gen"](input_text, max_length=max_len, num_return_sequences=1)
            st.success("Generation Complete!")
            st.code(result[0]["generated_text"], language="text")

# 2. Summarization
elif task == "Summarization":
    st.header("üìë Text Summarization (BART-Large-CNN)")
    st.markdown("Provide a long piece of text to generate a concise summary.")

    input_text = st.text_area(
        "Enter text to summarize:",
        """
        The Amazon rainforest is the largest tropical rainforest in the world.
        It covers over 5.5 million square kilometers and is primarily located
        within nine countries, with the majority in Brazil. The Amazon is
        crucial for the global climate, producing about 6% of the world's
        oxygen, and harbors an immense biodiversity. Deforestation, mainly for
        cattle ranching, poses a severe threat to this invaluable ecosystem.
        """,
        height=300
    )
    max_len = st.slider("Max Length of Summary", 10, 100, 50)
    min_len = st.slider("Min Length of Summary", 5, max_len - 5, 10)

    if st.button("Summarize"):
        with st.spinner("Summarizing..."):
            summary = pipes["summarizer"](input_text, max_length=max_len, min_length=min_len, do_sample=False)
            st.success("Summary Complete!")
            st.write(summary[0]["summary_text"])

# 3. Sentiment Analysis
elif task == "Sentiment Analysis":
    st.header("üòä Sentiment Analysis")
    st.markdown("Classify text as *POSITIVE* or *NEGATIVE*.")

    input_text = st.text_area(
        "Enter text:",
        "The food was incredibly delicious and the service was impeccable.",
        height=100
    )

    if st.button("Analyze Sentiment"):
        with st.spinner("Analyzing..."):
            result = pipes["sentiment"](input_text)[0]

            label = result['label']
            score = result['score']

            if label == 'POSITIVE':
                st.success(f"*Classification: {label}* (Confidence: {score:.4f})")
            else:
                st.error(f"*Classification: {label}* (Confidence: {score:.4f})")

# 4. Named Entity Recognition (NER)
elif task == "Named Entity Recognition (NER)":
    st.header("üìç Named Entity Recognition (NER)")
    st.markdown("Identify and classify entities (like people, places, organizations) in text.")

    input_text = st.text_area(
        "Enter text:",
        "Elon Musk founded SpaceX in California, purchasing a facility from Boeing.",
        height=100
    )

    if st.button("Identify Entities"):
        with st.spinner("Identifying..."):
            entities = pipes["ner"](input_text)
            st.success("Entities Identified!")

            # Display results in a table
            st.dataframe([
                {"Entity": ent['word'], "Label": ent['entity_group'], "Score": f"{ent['score']:.4f}"}
                for ent in entities
            ])

# 5. Grammar Correction
elif task == "Grammar Correction":
    st.header("‚úç Grammar Correction")
    st.markdown("Correct grammatical errors in the input text.")

    input_text = st.text_area(
        "Enter text with errors:",
        "She go to school every days, but he not going tomorrow.",
        height=100
    )

    if st.button("Correct Grammar"):
        with st.spinner("Correcting..."):
            result = pipes["grammar"](input_text)[0]["generated_text"]
            st.success("Correction Complete!")
            st.markdown(f"*Original:* {input_text}")
            st.markdown(f"*Corrected:*¬†{result}")